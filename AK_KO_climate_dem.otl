= V4 Outline MultiLine NoSorting TabWidth=30

H="First Heading"
/* 
********************HEADING******************** 

Project Name:

Date Started:

Primary Investigator:
Funding Source:

Created by:

Primary Analyst:
Secondary Analyst:

Datasets Used:

Simple Outline:


*/
 
//STATA
// Global Macros use $ symbol to be called. 

//Intermediate Data Path
global intpath "E:\nhats\data\Projects\..."

// Final Data Path
gloabl datapath "E:\nhats\data\Projects\..."

//Log files path
gloabl logpath "E:\nhats\data\Projects\..."


//SAS 


//Intermediate Data Path
//libname intpath "E:\nhats\data\Projects\..."

// Final Data Path
//libname datapath "E:\nhats\data\Projects\..."

//Log files path
//libname logpath "E:\nhats\data\Projects\..."


H="Generic template"
clear all
global ref_data "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data"

import excel "$ref_data\Multiple NHI for US counties - columbia .xlsx", sheet("Sheet1") firstrow case(lower)
//replace county=subinstr(county," ", "",.)
tempfile climate
save "`climate'"

clear all
import excel "$ref_data\fips_xwalk_new", sheet("Crosswalk") firstrow case(lower)
duplicates drop state county, force
replace county=lower(county)
//replace county=subinstr(county," ", "",.)
tempfile xwalk
save "`xwalk'"

import delimited "$ref_data\data.csv", varnames(1) clear
tempfile data
save "`data'"

use "`climate'", clear

merge m:1 state using "`data'", keep(matched) nogen

rename state state_name
rename code state
replace county=lower(county)
replace county=subinstr(county," city", "",.)
merge 1:1 state county using "`xwalk'", keep(matched) nogen

rename fipsstatecountycode fips


foreach x in wildfire volcano tornado snowfall landslide hurricane earthquake drought heatwave avalanche flood{
replace `x'="0" if `x'=="None"
replace `x'="1" if `x'=="Low"
replace `x'="1" if `x'=="Lo"
replace `x'="2" if `x'=="Medium"
replace `x'="3" if `x'=="High"
destring `x', replace
tab `x'
}


egen clim_prob=rowtotal(snowfall hurricane drought heatwave flood wildfire landslide)

tempfile climate_geo
save "`climate_geo'"

///////
use "D:\HRS\Shared\raw\HRS\hrs_restricted_2014\Detail\2014\hrsxdetail2014(2nd try unzip)\stata\HRSXGEO14b_R.dta", clear
rename wave core_year
destring core_year, replace
tempfile hrs_geo
save "`hrs_geo'", replace

use "D:\HRS\Shared\base_data\hrs_cleaned\core_00_to_14.dta" if core_year==2014, clear

merge 1:1 hhid pn using "D:\HRS\Shared\base_data\hrs_cleaned\restr_tracker_v2014.dta", keep(master matched) keepusing(birthday birthyr pn hhid race hispanic hisp_eth white black native_amer asian_pi other_race other_na_api_race death_date degree gender secu stratum study)

merge 1:1 hhid pn core_year using "D:\HRS\Shared\raw\HRS\hrs_public_2014\dementia\pdem_withvarnames_00_14.dta" , keep(master match) nogen keepusing(hhid pn core_year pdem)
gen prob_dem=.
replace prob_dem=0 if pdem<.5 & !missing(pdem)
replace prob_dem=1 if pdem>=.5 & !missing(pdem)

merge 1:1 hhid pn core_year using "`hrs_geo'", keep(master matched) nogen
rename stctyfips10 fips

merge m:1 fips using "`climate_geo'", keep(master matched) nogen
drop _merge
merge m:1 hhid pn year using "D:\HRS\Shared\base_data\hrs_cleaned\helper_hours_2016.dta", keep(master match) nogen

replace n_f=0 if n_f==.

gen any_formal=0
replace any_formal=1 if n_f>0 & n_f!=.

gen age= floor(core_year-birthyr)

gen education=.
replace education=0 if degree==0
replace education=1 if degree==1 | degree==2
replace education=2 if degree==3 | degree==4 | degree==5 | degree==6
label define deg 0 "less than high school" 1 "high school or equivalent" 2 "college or graduate"
label value education deg
tab education, gen (education)
label var education1 "Less than HS" 
label var education2 "HS or equivalent"
label var education3 "College or Graduate" 

label var hazards "Climate Index"

gen hazards_bin=0
replace hazards_bin=1 if inrange(hazards,14,22)
label var hazards_bin "Climate Hazard, binary"

label var clim_prob "Climate Index-restricted"

sum clim_prob, d
gen clim_prob_bin=0
replace clim_prob_bin=1 if inrange(clim_prob,12,18)
label var clim_prob_bin "Climate Hazard-restricted, binary"

gen white_other=0
replace white_oth=1 if white==1 | other_race==1

label var white_other "Non-Hispanic White or Other race"

gen flood_high=0 if flood!=.
replace flood_high=1 if flood==3
label var flood_high "Flood high Prev"
/*
gen liv_alone=.
replace liv_alone=0 if resspouse==1 | livealone==0
replace liv_alone=1 if resspouse==0 & livealone==1
*/
gen n=1
gen group1=1 if age>=65
gen group2=1 if group1==1 & prob_dem==0
gen group3=1 if group1==1 & prob_dem==1
gen group4=1 if age>=65 & hazards_bin==1
gen group5=1 if group1==1 & prob_dem==0 & hazards_bin==1
gen group6=1 if group1==1 & prob_dem==1 & hazards_bin==1


svyset secu [pweight=wgtr], strata(stratum) 



local r=1 
local c=1
mat tab=J(3, 3,.)

forvalues i=1/3{
	foreach x in hazards_bin clim_prob_bin flood_high{
	sum `x' [aw=wgtr] if group`i'==1
	mat tab[`r',`c']=`r(sum_w)'*`r(mean)'
	local r=`r'+1
	}
local c=`c'+1
local r=1
}
mat list tab

mat rownames tab= hazards_bin clim_prob_bin flood_high

frmttable using "D:\HRS\Projects\exploratory\AK_KO_climate_dem\logs\table_1.rtf", ///
statmat(tab) title("Population of 2014 Core, by Dementia Status") ///
ctitles("" "65+" "65+ without Dementia" "65+ with Dementia" ) varlabels ///
sdec(2) note("Using 2014 interview." "Climate Index/Hazard-restricted variable created using: tornado, snowfall, hurricane, drought, heatwave, flood, wildfire, and landslide" "Climate Hazard, binary had a threshold of 12 to be considered at risk; 14 is based off Columbia's methodology" "Climate Hazard-restricted, binary had a threshold of 14 to be considered at risk; 14 is based off the 75th percentile") replace


local cvars1 age
local ivars1 female white_other black hisp_eth education1 married medicaid fw_lowest fw_midlow fw_midhigh fw_highest srh_pf adl_independent_core resspouse any_formal
local cvars2 adl_index_core hazards clim_prob n_f
local ivars2 hazards_bin clim_prob_bin flood_high

local rn: word count `cvars1' `ivars1' `cvars2' `ivars2' 1

local r=1 
local c=1
mat tab=J(`rn', 3,.)
mat stars=J(`rn', 3,0)
forvalues i=1/3{
foreach x in `cvars1' {
	sum `x' [aw=wgtr] if group`i'==1
	mat tab[`r',`c']=`r(mean)'
		if `i'==1{
			ttest `x' if group1==1, by(prob_dem)
			mat stars[`r',`c'+2]=(r(p)<.05)+(r(p)<.01)
			} 
	local r=`r'+1
}

foreach x in `ivars1'{
	sum `x' [aw=wgtr] if group`i'==1
	mat tab[`r',`c']=`r(mean)'*100
		if `i'==1{
			tab `x' prob_dem if group1==1, chi2
			mat stars[`r',`c'+2]=(r(p)<.05)+(r(p)<.01)
			} 
	local r=`r'+1	
	}
	
foreach x in `cvars2' {
	sum `x' [aw=wgtr] if group`i'==1
	mat tab[`r',`c']=`r(mean)'
		if `i'==1{
			ttest `x' if group1==1, by(prob_dem)
			mat stars[`r',`c'+2]=(r(p)<.05)+(r(p)<.01)
			} 
	local r=`r'+1	
	}
	
foreach x in `ivars2'{
	sum `x' [aw=wgtr] if group`i'==1
	mat tab[`r',`c']=`r(mean)'*100
		if `i'==1{
			tab `x' prob_dem if group1==1, chi2
			mat stars[`r',`c'+2]=(r(p)<.05)+(r(p)<.01)
			} 
	local r=`r'+1
}

sum n [aw=wgtr] if group`i'==1 
mat tab[`r',`c']==`r(sum_w)'

local c=`c'+1
local r=1
}

mat rownames tab=`cvars1' `ivars1' `cvars2' `ivars2' "Population(N)"
mat colnames tab="65+" "65+ without Dementia" "65+ with Dementia"
mat list tab
mat list stars



frmttable using "D:\HRS\Projects\exploratory\AK_KO_climate_dem\logs\table_1.rtf", ///
statmat(tab) title("Characteristics of 2014 Core, by Dementia Status") ///
ctitles("" "65+" "65+ without Dementia" "65+ with Dementia" ) varlabels ///
sdec(2) note("Using 2014 interview." "Climate Index/Hazard-restricted variable created using: tornado, snowfall, hurricane, drought, heatwave, flood, wildfire, and landslide" "Climate Hazard, binary had a threshold of 12 to be considered at risk; 14 is based off Columbia's methodology" "Climate Hazard-restricted, binary had a threshold of 14 to be considered at risk; 14 is based off the 75th percentile") ///
annotate(stars) asymbol(*,**) addtable replace




local cvars1 age
local ivars1 female white_other black hisp_eth education1 married medicaid  fw_lowest fw_midlow fw_midhigh fw_highest srh_pf adl_independent_core resspouse any_formal
local cvars2 adl_index_core hazards clim_prob n_f
local ivars2 hazards_bin clim_prob_bin flood_high

local rn: word count `cvars1' `ivars1' `cvars2' `ivars2' 1

local r=1 
local c=1
mat tab=J(`rn', 3,.)
mat stars=J(`rn', 3,0)
forvalues i=4/6{
foreach x in `cvars1' {
	sum `x' [aw=wgtr] if group`i'==1
	mat tab[`r',`c']=`r(mean)'
		if `i'==4{
			ttest `x' if group4==1, by(prob_dem)
			mat stars[`r',`c'+2]=(r(p)<.05)+(r(p)<.01)
			} 
	local r=`r'+1
}

foreach x in `ivars1'{
	sum `x' [aw=wgtr] if group`i'==1
	mat tab[`r',`c']=`r(mean)'*100
		if `i'==4{
			tab `x' prob_dem if group4==1, chi2
			mat stars[`r',`c'+2]=(r(p)<.05)+(r(p)<.01)
			} 
	local r=`r'+1	
	}
	
foreach x in `cvars2' {
	sum `x' [aw=wgtr] if group`i'==1
	mat tab[`r',`c']=`r(mean)'
		if `i'==4{
			ttest `x' if group4==1, by(prob_dem)
			mat stars[`r',`c'+2]=(r(p)<.05)+(r(p)<.01)
			} 
	local r=`r'+1	
	}
	
foreach x in `ivars2'{
	sum `x' [aw=wgtr] if group`i'==1
	mat tab[`r',`c']=`r(mean)'*100
		if `i'==4{
			tab `x' prob_dem if group4==1, chi2
			mat stars[`r',`c'+2]=(r(p)<.05)+(r(p)<.01)
			} 
	local r=`r'+1
}

sum n [aw=wgtr] if group`i'==1 
mat tab[`r',`c']==`r(sum_w)'

local c=`c'+1
local r=1
}

mat rownames tab=`cvars1' `ivars1' `cvars2' `ivars2' "Population(N)"
mat colnames tab="65+" "65+ without Dementia" "65+ with Dementia"
mat list tab
mat list stars



frmttable using "D:\HRS\Projects\exploratory\AK_KO_climate_dem\logs\table_1.rtf", ///
statmat(tab) title("Characteristics of 2014 Core, by Dementia Status restricted to people living in vulnerable areas") ///
ctitles("" "65+" "65+ without Dementia" "65+ with Dementia" ) varlabels ///
sdec(2) note("Using 2014 interview." "Climate Index/Hazard-restricted variable created using: tornado, snowfall, hurricane, drought, heatwave, flood, wildfire, and landslide" "Climate Hazard, binary had a threshold of 12 to be considered at risk; 14 is based off  Columbia's methodology" "Climate Hazard-restricted, binary had a threshold of 14 to be considered at risk; 14 is based off the 75th percentile" "Vulnerable areas were defined by Columbia") ///
annotate(stars) asymbol(*,**) addtable replace





H="HRS Geographic & ADI "
/*
use ADI_2013_v2.0 and ADI_2015! 
FIPS: The block group Census ID: state(2chars)county(3chars)Tract(6chars)Block(1char)= 12chars total  
adi_natrank: nat'l percentile of block group ADI score - should use this ranking! 
adi_staterank: state specific decile of block group ADI score (ranking constructed for each state alone w/o consideration of national ADI, according to Neighborhood Atlas)
*/

/*
tostring to see all of the fips 
get average of ADI scores by each county 
merge on county fips
merge from there 
substring, take last 4 digits 
*/

global ref_data "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data"

*******************CLEAN & SET UP ADI 2013 v.2 DATA***************************
use "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data\ADI_2013_v2.0.dta", clear
*done to see full fips #s 
tostring fips, replace format (%15.0gc)

*add leading 0 to fipsnew to make all fips 12 chars long
gen zfips = string(real(fips),"%012.0f")

*keep state& ctfips&fips, which is first 11 chars (statecountyfips)
gen stctytct = substr(zfips,1,11)


*find adi_natranks that are nonnumeric 
codebook adi_natrank if missing(real(adi_natrank))
/*PH: suppression due to low population and/or housing 
GQ: suppression due to high group quarters population 
PH-GQ: suppresion due to both 
*/

gen numadi = adi_natrank 
replace numadi = "." if numadi == "PH" 
replace numadi = "." if numadi == "GQ" 
replace numadi = "." if numadi == "GQ-PH"
codebook numadi if missing(real(numadi))
destring numadi, replace
codebook numadi

*use cmd: collapse to get all the same observations to 1 obsv & get avge of adi 
collapse (mean) adi2013 = numadi, by(stctytct)
*returns only avge natrank & stctytct 

save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data\tomerge_adi2013.dta", replace

***********************CLEAN & SET UP ADI 2015 DATA***************************
use "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data\ADI_2015.dta", clear 

*done to see full fips #s 
tostring fips, replace format (%15.0gc)

*add leading 0 to fipsnew to make all fips 12 chars long
gen zfips = string(real(fips),"%012.0f")

*keep state& ctfips, which is first 5 chars (statecountyfips)
gen stctytct = substr(zfips,1,11)

*find adi_natranks that are nonnumeric 
codebook adi_natrank if missing(real(adi_natrank))
/*PH: suppression due to low population and/or housing 
GQ: suppression due to high group quarters population 
PH-GQ: suppresion due to both 
*/

gen numadi = adi_natrank 
replace numadi = "." if numadi == "PH" 
replace numadi = "." if numadi == "GQ" 
replace numadi = "." if numadi == "GQ-PH"
codebook numadi if missing(real(numadi))
destring numadi, replace
codebook numadi

*use cmd: collapse to get all the same observations to 1 obsv & get avge of adi 
collapse (mean) adi2015 = numadi, by(stctytct)
*returns only avge natrank & stctytct 

save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data\tomerge_adi2015.dta", replace

***********************MERGE HRS DATA TO 2013 & 2015 ADI ***************************

use "D:\HRS\Shared\raw\HRS\hrs_restricted_2014\Detail\2014\hrsxdetail2014(2nd try unzip)\stata\HRSXGEO14b_R.dta", clear
rename wave core_year
destring core_year, replace
tempfile hrs_geo
save "`hrs_geo'", replace

use "D:\HRS\Shared\base_data\hrs_cleaned\core_00_to_14.dta" if core_year==2014, clear

merge 1:1 hhid pn using "D:\HRS\Shared\base_data\hrs_cleaned\restr_tracker_v2014.dta", keep(master matched) keepusing(birthday birthyr pn hhid race hispanic hisp_eth white black native_amer asian_pi other_race other_na_api_race death_date degree gender secu stratum study)

gen age=core_year-birthyr 

merge 1:1 hhid pn core_year using "D:\HRS\Shared\raw\HRS\hrs_public_2014\dementia\pdem_withvarnames_00_14.dta" , keep(master match) nogen keepusing(hhid pn core_year pdem)
gen prob_dem=.
replace prob_dem=0 if pdem<.5 & !missing(pdem)
replace prob_dem=1 if pdem>=.5 & !missing(pdem)

merge 1:1 hhid pn core_year using "`hrs_geo'", keep(master matched) nogen
rename stctyfips10 fips
gen stctytct = linkcen2010

merge m:1 stctytct using "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data\tomerge_adi2015.dta", keep(master matched) nogen

merge m:1 stctytct using "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data\tomerge_adi2013.dta", keep(master matched) nogen 

*17,900 matched on statecountytracts and 848 not matched  

assert stctytct == linkcen2010
drop stctytct

xtile adi2013_quin= adi2013, nq(5)
xtile adi2015_quin= adi2015, nq(5)


save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\adi_hrsgeo", replace


drop  rescode urbrur1993 urbrur2003 urbrur2013 countyname10 countyname10 linkcen1990 linkcen2000 linkcen2010 tract10 cntyfips10 stfips10 fips zipcode stateusps c_ivw_month c_ivw_day birthday c_ivw_day_imp c_ivw_date birthday birthyr native_amer asian_pi  other_na_api_race death_date study race adi2013 adi2015





save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\adi_hrsgeo_public", replace


H="FEMA Disaster Declaration "
/*
Cleaning FEMA disaster declarations
Merge in crosswalk fips & give counties w/o disasters a 0 
keep 2013-2015 data only 
get basic stats on # of disasters per county, per year, types of disasters 
*/

global ref_data "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data"

*import crosswalk data 
import excel "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data\Crosswalk Disasters_CountyFips.xlsx", sheet("Sheet1") firstrow case(lower) allstring clear

gen stctyfips = string(real(fips), "%05.0f")
sort state stctyfips
duplicates list state stctyfips name
duplicates tag state stctyfips, gen(dups)
tab stctyfips name if dups 
duplicates drop state stctyfips, force
*dropped 3 
save "crosswalk", replace

*import FEMA Disaster Declarations 
import delimited "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data\DisasterDeclarationsSummaries.csv", clear

tab fydeclared if fydeclared >=2013 & fydeclared <=2015
*gives 1200 obsvns in 2013, 765 in 2014, 869 in 2015

keep if fydeclared == 2013|fydeclared == 2014|fydeclared == 2015

tostring fipsstatecode, replace

gen zstatefips = fipsstatecode
replace  zstatefips = "0"+ fipsstatecode if length(fipsstatecode) == 1

tostring fipscountycode, replace
gen zcountyfips = fipscountycode 
replace zcountyfips = "00"+ fipscountycode if length(fipscountycode) == 1
replace zcountyfips = "0"+ fipscountycode if length(fipscountycode) == 2

gen stctyfips = zstatefips+zcountyfips

save "femadisasterdeclarations", replace

sort state stctyfips
merge m:1 state stctyfips using "crosswalk.dta"

*see which fips were onlyl in the fema disaster declarations 
list stctyfips if _merge == 1

replace disasternumber = 0 if disasternumber == . 

keep if  inlist(incidenttype, "Fire", "Flood", "Hurricane", "Severe Ice Storm", "Severe Storm(s)", "Snow", "Tornado", "Typhoon")

encode incidenttype, gen (incidtype)
tab incidtype, nolabel  

*want count of incident types (disasters) by stctyfips & yr
forvalues i = 1/8{
gen indicator`i' = incidtype == `i'
}

tab1 indicator*

forvalues i = 1/8{
egen indyr`i' = total(indicator`i'), by(stctyfips fydeclared)	
}

forvalues i = 1/8{
sum indyr`i' if indyr`i' != 0
}

keep fydeclared stctyfips indyr* 

rename fydeclared year
duplicates report stctyfips year 

duplicates drop 

reshape wide indyr*, i(stctyfips) j(year)

rename stctyfips fips

merge 1:m fips using "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\adi_hrsgeo.dta", gen(a)


drop  rescode urbrur1993 urbrur2003 urbrur2013 countyname10 countyname10 linkcen1990 linkcen2000 linkcen2010 tract10 cntyfips10 stfips10 fips zipcode stateusps c_ivw_month c_ivw_day birthday c_ivw_day_imp c_ivw_date birthday birthyr native_amer asian_pi  other_na_api_race death_date study race fips indyr7* indyr8*


save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\climate_merged_public.dta", replace

H="xxxxxEBL merging multiple years"
*use "D:\HRS\Shared\base_data\hrs_cleaned\core_00_to_14_unr.dta", clear
//note--half of disaster counties don't match with anybody in HRS, just 5 counties in HRS don't match (74 obs total)
use "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\climate_clean_new", clear
rename st stctyfips10 
tempfile t1
save `t1'

//get a dataset with all of the interviews, core and exit
use "D:\HRS\Shared\base_data\hrs_cleaned\core_00_to_14.dta", clear
gen ivw_type=1
append using "D:\HRS\Shared\base_data\hrs_cleaned\exit_02_to_16_dt.dta"
replace ivw_type=2 if missing(ivw_type)
label define ivw_type 1 "Core" 2 "Exit"
replace core_year=exit_year if missing(core_year)
merge m:1 id using "D:\HRS\Shared\base_data\hrs_cleaned\death_date_2015.dta", keep(match master)
replace c_ivw_date=death_all if ivw_type==2
keep id core_year c_ivw_date ivw_type
tempfile ivws
save `ivws'

use hhid pn stcty wave using "D:\HRS\Shared\raw\HRS\hrs_restricted_2014\Detail\2014\hrsxdetail2014(2nd try unzip)\stata\HRSXGEO14b_R.dta", clear
gen id=hhid+pn
rename wave core_year
destring core_year, replace
gen wave=(core_year-1990)/2
merge 1:1 id core_year using `ivws', keep(match) nogen
sort id core_year
by id: gen ivw_date_n1=c_ivw_date[_n-1]

forvalues i=5/12 {
	preserve
	keep if wave==`i'
	joinby stc using `t1', unmatched(both) _merge(_merge)
	keep if _merge==3
	keep if inrange(inc_date,ivw_date_n1,c_ivw_date-1)
	*keep if inrange(inc_date,c_ivw_date-730,c_ivw_date-1)
	drop inc_date
	duplicates drop
	tempfile t`i'
	save `t`i''
	restore
}

clear 
forvalues i=5/12 {
	append using `t`i''
}

keep id core_year mete* hydro geo climate ivw_type
duplicates drop
duplicates report id core_year
merge m:1 id core_year using `ivws', nogen keepusing(ivw_type)

foreach x of varlist mete_storm mete_ext hydro geo climate {
replace `x'=0 if missing(`x') 
replace `x'=. if core_year==1998
by id core_year, sort: egen a=max(`x')
replace `x'=a
drop a
}
duplicates drop

egen ind_disaster=rowmax(mete_* hydro geo climate)
rename core_year year
order id year ivw_type

drop if ivw_type==2
drop ivw_type
save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\fema_dis_00_14.dta", replace

H="xxxxxEBL merging multiple years by n1 address"
*use "D:\HRS\Shared\base_data\hrs_cleaned\core_00_to_14_unr.dta", clear
//note--half of disaster counties don't match with anybody in HRS, just 5 counties in HRS don't match (74 obs total)
use "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\climate_clean_new", clear
rename st stctyfips10 
tempfile t1
save `t1'

//get a dataset with all of the interviews, core and exit
use "D:\HRS\Shared\base_data\hrs_cleaned\core_00_to_16.dta", clear
gen ivw_type=1
append using "D:\HRS\Shared\base_data\hrs_cleaned\exit_02_to_16_dt.dta"
replace ivw_type=2 if missing(ivw_type)
label define ivw_type 1 "Core" 2 "Exit"
replace core_year=exit_year if missing(core_year)
merge m:1 id using "D:\HRS\Shared\base_data\hrs_cleaned\death_date_2016.dta", keep(match master)
replace c_ivw_date=death_all if ivw_type==2
gen ind_died_24m=death_all<=c_ivw_date+730

keep id core_year c_ivw_date ivw_type death_all ind_died_24m
keep if ivw_type==1
tempfile ivws
save `ivws'

use hhid pn stcty year using "D:\HRS\Shared\raw\HRS\hrs_restricted_2016\GeoCode\Detail\2016\hrsxdetail2016\stata\HRSXGEO16V7B_R.dta", clear
gen id=hhid+pn
rename wave core_year
destring core_year, replace
gen wave=(core_year-1990)/2
merge 1:1 id core_year using `ivws', keep(match) nogen
sort id core_year
by id: gen ivw_date_n1=c_ivw_date

forvalues i=5/12 {
	preserve
	keep if wave==`i'
	joinby stc using `t1', unmatched(both) _merge(_merge)
	keep if _merge==3
	keep if inrange(inc_date,ivw_date_n1,ivw_date_n1+730)
	drop if death_all<inc_date & !missing(inc_date)
	drop inc_date death_all
	duplicates drop
	tempfile t`i'
	save `t`i''
	restore
}

clear 
forvalues i=5/12 {
	append using `t`i''
}

keep id core_year mete* hydro geo climate ivw_type 
duplicates drop
duplicates report id core_year
merge m:1 id core_year using `ivws', nogen keepusing(ivw_type ind_died_24m)


foreach x of varlist mete_storm mete_ext hydro geo climate {
replace `x'=0 if missing(`x') 
replace `x'=. if core_year==1998
by id core_year, sort: egen a=max(`x')
replace `x'=a
drop a
}
duplicates drop

egen ind_disaster=rowmax(mete_* hydro geo climate)
rename core_year year
order id year ivw_type

drop if ivw_type==2
drop ivw_type
save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\fema_dis_00_14_n1loc.dta", replace

H="xxxxxnew merge on nov 4"
*use "D:\HRS\Shared\base_data\hrs_cleaned\core_00_to_14_unr.dta", clear
//note--half of disaster counties don't match with anybody in HRS, just 5 counties in HRS don't match (74 obs total)
use "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\climate_clean_new_06242020", clear
rename st stctyfips10 
tempfile t1
save `t1'

//get a dataset with all of the interviews, core and exit
use "D:\HRS\Shared\base_data\hrs_cleaned\core_00_to_16.dta", clear
gen ivw_type=1
append using "D:\HRS\Shared\base_data\hrs_cleaned\exit_02_to_16_dt.dta"
replace ivw_type=2 if missing(ivw_type)
label define ivw_type 1 "Core" 2 "Exit"
replace core_year=exit_year if missing(core_year)
merge m:1 id using "D:\HRS\Shared\base_data\hrs_cleaned\death_date_2016.dta", keep(match master)
replace c_ivw_date=death_all if ivw_type==2
gen ind_died_24m=death_all<=c_ivw_date+730

keep id core_year c_ivw_date ivw_type death_all ind_died_24m
keep if ivw_type==1
tempfile ivws
save `ivws'

use hhid pn stcty year using "D:\HRS\Shared\raw\HRS\hrs_restricted_2016\GeoCode\Detail\2016\hrsxdetail2016\stata\HRSXGEO16V7B_R.dta", clear
gen id=hhid+pn
rename year core_year
destring core_year, replace
gen wave=(core_year-1990)/2
merge 1:1 id core_year using `ivws', keep(match) nogen
sort id core_year
by id: gen ivw_date_n1=c_ivw_date

forvalues i=5/12 {
	preserve
	keep if wave==`i'
	joinby stc using `t1', unmatched(both) _merge(_merge)
	keep if _merge==3
	keep if inrange(inc_date,ivw_date_n1,ivw_date_n1+730)
	drop if death_all<inc_date & !missing(inc_date)
	drop inc_date death_all
	duplicates drop
	tempfile t`i'
	save `t`i''
	restore
}

clear 
forvalues i=5/12 {
	append using `t`i''
}

keep id core_year hurricane sev_storm mete* hydro geo climate ivw_type 
duplicates drop
duplicates report id core_year
merge m:1 id core_year using `ivws', nogen keepusing(ivw_type ind_died_24m)


foreach x of varlist hurricane sev_storm mete_storm mete_ext hydro geo climate {
replace `x'=0 if missing(`x') 
replace `x'=. if core_year==1998
by id core_year, sort: egen a=max(`x')
replace `x'=a
drop a
}
duplicates drop

egen ind_disaster=rowmax(hurricane sev_storm mete_* hydro geo climate)
rename core_year year
order id year ivw_type

drop if ivw_type==2
drop ivw_type
save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\fema_dis_00_14_n1loc_110420.dta", replace

H="xxxxxMH adding vars"
use "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data\zip fips.dta", clear

tostring zipcode, replace

replace zipcode="00"+zipcode if strlen(zipcode)==3
replace zipcode="0"+zipcode if strlen(zipcode)==4

tempfile zipcode
save `zipcode'

import excel "D:\SSH Transfer\New Files moved on\Mohammed\20200728\ruralurbancodes2013.xls", sheet("Rural-urban Continuum Code 2013") firstrow case(lower) clear

tempfile metro
save `metro'


use "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\fema_dis_00_14_n1loc_110420.dta", clear

destring id, replace

merge m:1 id using "D:\HRS\Shared\base_data\hrs_cleaned\restr_tracker_v2014.dta", keep(master matched) nogen 


gen state="."
gen zipcode="."
replace state=stateusps98 if year==1998
replace zipcode=zipcode98 if year==1998

foreach i in 00 02 04 06 08 10 12 14{
	replace state=stateusps`i' if year==20`i'
	replace zipcode=zipcode`i' if year==20`i'
}
sort id year
by id: carryforward id year, replace 

gen region=1 if inlist(state, "CT","ME","MA","NH","RI","VT","NJ","NY","PA")
replace region=2 if inlist(state, "IN","IL","MI","OH","WI","IA","KS","MN","MO")
replace region=2 if inlist(state,"NE","ND","SD")
replace region=3 if inlist(state, "DE","DC","FL","GA","MD","NC","SC","VA","WV")
replace region=3 if inlist(state,"AL","KY","MS","TN", "AR","LA","OK","TX")
replace region=4 if inlist(state, "AZ","CO","ID","NM","MT","UT","NV","WY","AK")
replace region=4 if inlist(state,"CA","HI","OR","WA")

merge m:1 zipcode using "`zipcode'", keep(master matched) nogen

merge m:1 fips using `metro', keep(master matched) nogen

gen metro=0
replace metro=1 if inlist(rucc_2013, 1,2 ,3)


keep id-ind_disaster white black other_na_api_race region hisp_eth metro

save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\fema_dis_00_14_n1loc_110420.dta", replace 

H="Merging multiple years by n1 address"
*use "D:\HRS\Shared\base_data\hrs_cleaned\core_00_to_14_unr.dta", clear
//note--half of disaster counties don't match with anybody in HRS, just 5 counties in HRS don't match (74 obs total)
use "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\climate_clean_new_06242020", clear
rename st stctyfips10 
tempfile t1
save `t1'

//get a dataset with all of the interviews, core and exit
use "D:\HRS\Shared\base_data\hrs_cleaned\core_00_to_16.dta", clear
gen ivw_type=1
append using "D:\HRS\Shared\base_data\hrs_cleaned\exit_02_to_16_dt.dta"
replace ivw_type=2 if missing(ivw_type)
label define ivw_type 1 "Core" 2 "Exit"
replace core_year=exit_year if missing(core_year)
merge m:1 id using "D:\HRS\Shared\base_data\hrs_cleaned\death_date_2016.dta", keep(match master)
replace c_ivw_date=death_all if ivw_type==2
gen ind_died_24m=death_all<=c_ivw_date+730

keep id core_year c_ivw_date ivw_type death_all ind_died_24m
keep if ivw_type==1
tempfile ivws
save `ivws'

use hhid pn stcty year using "D:\HRS\Shared\raw\HRS\hrs_restricted_2016\GeoCode\Detail\2016\hrsxdetail2016\stata\HRSXGEO16V7B_R.dta", clear
gen id=hhid+pn
rename year core_year
destring core_year, replace
gen wave=(core_year-1990)/2
merge 1:1 id core_year using `ivws', keep(match) nogen
sort id core_year
by id: gen ivw_date_n1=c_ivw_date

forvalues i=5/13 {
	preserve
	keep if wave==`i'
	joinby stc using `t1', unmatched(both) _merge(_merge)
	keep if _merge==3
	keep if inrange(inc_date,ivw_date_n1,ivw_date_n1+730)
	codebook id if death_all<inc_date & !missing(inc_date)
	drop if death_all<inc_date & !missing(inc_date)
	drop inc_date death_all
	duplicates drop
	tempfile t`i'
	save `t`i''
	restore
}
//find the number of unique people who died before disaster
di 46+204+218+252+293+264+287+449+272

clear 
forvalues i=5/13 {
	append using `t`i''
}

keep id hhid pn core_year hurricane sev_storm mete* hydro geo climate ivw_type 
duplicates drop
duplicates report id core_year
merge m:1 id core_year using `ivws', nogen keepusing(ivw_type ind_died_24m)


foreach x of varlist hurricane sev_storm mete_storm mete_ext hydro geo climate {
replace `x'=0 if missing(`x') 
replace `x'=. if core_year==1998
by id core_year, sort: egen a=max(`x')
replace `x'=a
drop a
}
duplicates drop

egen ind_disaster=rowmax(hurricane sev_storm mete_* hydro geo climate)
rename core_year year
order id year ivw_type

drop if ivw_type==2
drop ivw_type
save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\fema_dis_00_16_n1loc_111220.dta", replace

H="adding vars"
use "D:\HRS\Shared\raw\HRS\hrs_restricted_2016\GeoCode\Detail\2016\hrsxdetail2016\stata\HRSXGEO16V7B_R.dta", clear
gen id=hhid+pn

tempfile geo
save `geo'

use "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\ref_data\zip fips.dta", clear

tostring zipcode, replace

replace zipcode="00"+zipcode if strlen(zipcode)==3
replace zipcode="0"+zipcode if strlen(zipcode)==4

tempfile zipcode
save `zipcode'

import excel "D:\SSH Transfer\New Files moved on\Mohammed\20200728\ruralurbancodes2013.xls", sheet("Rural-urban Continuum Code 2013") firstrow case(lower) clear

tempfile metro
save `metro'


use "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\fema_dis_00_16_n1loc_111220.dta", clear


merge 1:1 id year using "`geo'", keep(master matched)  nogen


gen state=stateusps


gen region=1 if inlist(state, "CT","ME","MA","NH","RI","VT","NJ","NY","PA")
replace region=2 if inlist(state, "IN","IL","MI","OH","WI","IA","KS","MN","MO")
replace region=2 if inlist(state,"NE","ND","SD")
replace region=3 if inlist(state, "DE","DC","FL","GA","MD","NC","SC","VA","WV")
replace region=3 if inlist(state,"AL","KY","MS","TN", "AR","LA","OK","TX")
replace region=4 if inlist(state, "AZ","CO","ID","NM","MT","UT","NV","WY","AK")
replace region=4 if inlist(state,"CA","HI","OR","WA")

merge m:1 zipcode using "`zipcode'", keep(master matched) nogen

merge m:1 fips using `metro', keep(master matched) nogen

gen metro=0
replace metro=1 if inlist(rucc_2013, 1,2 ,3)

gen hhidpn=id

destring id, replace
merge m:1 id using "D:\HRS\Shared\base_data\hrs_cleaned\restr_tracker_v2014.dta", keep(master matched) nogen

keep hhidpn id-ind_disaster white black other_na_api_race region hisp_eth metro

save "D:\HRS\Projects\exploratory\AK_KO_climate_dem\data\final_data\fema_dis_00_16_n1loc_111220.dta", replace 

H="Change log"
********************Change Log******************** 



Updates:

11/12/2020 MH
------------
Updating the code and fixing the restricted file issue. 

11/4/2020 MH
------------
Adding in 2016 HRS data. 

5/7/2020 CY
-------------
Merged FEMA disaster declarations between each interview


3/12/2020 CY
-------------
Merged ADI & HRS_GEO data on state,county,&tract

12/02/2019 MH
------------
Created table. Added in variables. Created new hazards measurement. 

11/29/2019 MH
------------
Started project. Merged data.

*/